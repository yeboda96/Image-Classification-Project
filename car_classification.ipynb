{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "car classification",
      "version": "0.3.2",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yeboda96/Image-Classification-Project/blob/master/car_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "6JmF_9B0Mydy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GA3FohAMSj7T",
        "colab_type": "code",
        "outputId": "cb113361-8571-4016-d2a1-bf5678164705",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 160
        }
      },
      "cell_type": "code",
      "source": [
        "import scipy.io\n",
        "import shutil\n",
        "import os\n",
        "\n",
        "\n",
        "mat = scipy.io.loadmat('drive/My Drive/cars_train_annos.mat')\n",
        "# print(mat['annotations'])\n",
        "training_class = mat['annotations']['class']\n",
        "training_fname = mat['annotations']['fname']\n",
        "training_x1 = mat['annotations']['bbox_x1']\n",
        "training_y1 = mat['annotations']['bbox_y1']\n",
        "training_x2 = mat['annotations']['bbox_x2']\n",
        "training_y2 = mat['annotations']['bbox_y2']\n",
        "\n",
        "mat = scipy.io.loadmat('drive/My Drive/cars_test_annos_withlabels.mat')\n",
        "print(mat['annotations'])\n",
        "testing_class = mat['annotations']['class']\n",
        "testing_fname = mat['annotations']['fname']\n",
        "# print(testing_fname)\n",
        "# print(testing_class)\n",
        "\n",
        "training_source = 'drive/My Drive/cars_train/' # specify source training image path\n",
        "training_output = 'drive/My Drive/train_folder/' # specify target trainig image path (trainig images need to be orgnized to specific structure)\n",
        "for idx, cls in enumerate(training_class[0]):\n",
        "    cls = cls[0][0]\n",
        "    fname = training_fname[0][idx][0]\n",
        "    # print(cls)\n",
        "    output_path = os.path.join(training_output, str(cls))\n",
        "    if not os.path.exists(output_path):\n",
        "        os.mkdir(output_path)\n",
        "    shutil.copy(os.path.join(training_source, fname), os.path.join(output_path, fname))\n",
        "\n",
        "testing_source = 'drive/My Drive/cars_test/' # specify source testing image path\n",
        "testing_output = 'drive/My Drive/test_folder/' # specify target testing image path (testing images need to be orgnized to specific structure)\n",
        "for idx, cls in enumerate(testing_class[0]):\n",
        "    cls = cls[0][0]\n",
        "    fname = testing_fname[0][idx][0]\n",
        "    output_path = os.path.join(testing_output, str(cls))\n",
        "    if not os.path.exists(output_path):\n",
        "        os.mkdir(output_path)\n",
        "    shutil.copy(os.path.join(testing_source, fname), os.path.join(output_path, fname))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[(array([[30]], dtype=uint8), array([[52]], dtype=uint8), array([[246]], dtype=uint8), array([[147]], dtype=uint8), array([[181]], dtype=uint8), array(['00001.jpg'], dtype='<U9'))\n",
            "  (array([[100]], dtype=uint8), array([[19]], dtype=uint8), array([[576]], dtype=uint16), array([[203]], dtype=uint8), array([[103]], dtype=uint8), array(['00002.jpg'], dtype='<U9'))\n",
            "  (array([[51]], dtype=uint8), array([[105]], dtype=uint8), array([[968]], dtype=uint16), array([[659]], dtype=uint16), array([[145]], dtype=uint8), array(['00003.jpg'], dtype='<U9'))\n",
            "  ...\n",
            "  (array([[33]], dtype=uint8), array([[27]], dtype=uint8), array([[602]], dtype=uint16), array([[252]], dtype=uint8), array([[17]], dtype=uint8), array(['08039.jpg'], dtype='<U9'))\n",
            "  (array([[33]], dtype=uint8), array([[142]], dtype=uint8), array([[521]], dtype=uint16), array([[376]], dtype=uint16), array([[38]], dtype=uint8), array(['08040.jpg'], dtype='<U9'))\n",
            "  (array([[77]], dtype=uint8), array([[73]], dtype=uint8), array([[506]], dtype=uint16), array([[380]], dtype=uint16), array([[32]], dtype=uint8), array(['08041.jpg'], dtype='<U9'))]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Ll778O7XWLN0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.preprocessing import image\n",
        "from keras.applications import vgg16\n",
        "from keras.applications import vgg19\n",
        "from keras.applications import resnet50\n",
        "from keras.applications import inception_v3\n",
        "from keras.layers import GlobalAveragePooling2D, Dense, Dropout, Flatten\n",
        "from keras.models import Model,Sequential\n",
        "from keras import optimizers\n",
        "from keras.callbacks import TensorBoard, ModelCheckpoint\n",
        "import argparse\n",
        "from time import time\n",
        "\n",
        "from skimage import exposure, color\n",
        "\n",
        "from keras import backend as K\n",
        "K.set_image_dim_ordering('tf')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RNb0uGI7uHxF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def init_model(train_dir,val_dir,batch_size=16,model_name='vgg16',num_class=2,img_size=224):\n",
        "    \"\"\"\n",
        "    initialize cnn model and training and validation data generator\n",
        "    parms:\n",
        "        args: parsed commandline arguments\n",
        "    return:\n",
        "        model: initialized model\n",
        "        train_generator: training data generator\n",
        "        validation_generator: validation data generator\n",
        "    \"\"\"\n",
        "    \n",
        "\n",
        "    print('loading the model and the pre-trained weights...')\n",
        "\n",
        "    # load base model\n",
        "    if model_name == 'vgg16':\n",
        "        base_model = vgg16.VGG16(include_top=False, weights='imagenet', input_shape = (224,224,3)) # need specify input_shape\n",
        "        # this preprocess_input is the default preprocess func for given network, you can change it or implement your own \n",
        "        # use inception_v3 preprocess for vgg16, it seems that it works better than vgg16.preprocess_input\n",
        "        preprocess_input = inception_v3.preprocess_input \n",
        "    \n",
        "    elif model_name == 'inception_v3':\n",
        "        base_model = inception_v3.InceptionV3(include_top=False, weights='imagenet', input_shape = (224,224,3)) # need specify input_shape\n",
        "        preprocess_input = inception_v3.preprocess_input\n",
        "    elif model_name == 'resnet50':\n",
        "        base_model = resnet50.ResNet50(include_top=False, weights='imagenet', input_shape = (224,224,3)) # need specify input_shape\n",
        "        preprocess_input = resnet50.preprocess_input\n",
        "\n",
        "    \n",
        "    \n",
        "    \n",
        "    \n",
        "    # initalize training image data generator\n",
        "    # you can also specify data augmentation here\n",
        "    train_datagen = image.ImageDataGenerator(\n",
        "        # width_shift_range=0.1,\n",
        "        # height_shift_range=0.1,\n",
        "        # samplewise_center=True,\n",
        "        # samplewise_std_normalization=True,\n",
        "        # rescale=1./255,\n",
        "        preprocessing_function=preprocess_input, # preprocess_input,\n",
        "        # rotation_range=30,\n",
        "        # shear_range=0.1,\n",
        "        # zoom_range=0.1,\n",
        "        # vertical_flip=True,\n",
        "        horizontal_flip=True\n",
        "        )\n",
        "\n",
        "    # initalize validation image data generator\n",
        "    # you can also specify data augmentation here\n",
        "    validation_datagen = image.ImageDataGenerator(\n",
        "        # samplewise_center=True,\n",
        "        # samplewise_std_normalization=True\n",
        "        # rescale=1./255\n",
        "        preprocessing_function=preprocess_input # preprocess_input\n",
        "        )\n",
        "\n",
        "    train_generator = train_datagen.flow_from_directory(\n",
        "        train_dir,\n",
        "        # color_mode='grayscale', # 'rgb'\n",
        "        target_size=(img_size, img_size),\n",
        "        batch_size=batch_size,\n",
        "        class_mode='categorical')\n",
        "\n",
        "    validation_generator = validation_datagen.flow_from_directory(\n",
        "        val_dir,\n",
        "        # color_mode='grayscale',  # 'rgb'\n",
        "        target_size=(img_size, img_size),\n",
        "        batch_size=batch_size,\n",
        "        class_mode='categorical')\n",
        "\n",
        "    # fix base_model layers\n",
        "    for layer in base_model.layers:\n",
        "        layer.trainable = False\n",
        "\n",
        "    # added some customized layers for your own data\n",
        "    x = base_model.output\n",
        "    if model_name == 'vgg16':\n",
        "        x = Flatten(name='flatten')(x)\n",
        "        x = Dense(512, activation='relu', name='fc1-pretrain')(x)\n",
        "        x = Dense(256, activation='relu', name='fc2-pretrain')(x)\n",
        "        x = Dropout(0.5, name='dropout')(x)\n",
        "        \n",
        "    elif model_name == 'inception_v3':\n",
        "        x = GlobalAveragePooling2D(name='avg_pool')(x)\n",
        "        x = Dense(256, activation='relu', name='fc1-pretrain')(x)\n",
        "    elif model_name == 'resnet50':\n",
        "        x = GlobalAveragePooling2D(name='avg_pool')(x)\n",
        "        x = Dense(256, activation='relu', name='fc1-pretrain')(x)\n",
        "        \n",
        "        \n",
        "    \n",
        "\n",
        "    # added softmax layer\n",
        "    predictions = Dense(num_class, activation='softmax', name='predictions')(x)\n",
        "\n",
        "    model = Model(inputs=base_model.input, outputs=predictions)\n",
        "    model.compile(loss=\"categorical_crossentropy\", optimizer=optimizers.Adam(), metrics=[\"accuracy\"])\n",
        "\n",
        "    return model, train_generator, validation_generator"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "n_r-lCXKuXbB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def train(model, train_generator, validation_generator, num_class= 2,model_name='vgg16', batch_size=16, epochs=30, suffix='laioffer'):\n",
        "    \"\"\"\n",
        "    train the model\n",
        "    parms:\n",
        "        model: initialized model\n",
        "        train_generator: training data generator\n",
        "        validation_generator: validation data generator\n",
        "        args: parsed command line arguments\n",
        "    return:\n",
        "    \"\"\"\n",
        "    # define number of steps/iterators per epoch\n",
        "    stepsPerEpoch = train_generator.samples / batch_size\n",
        "    validationSteps= validation_generator.samples / batch_size\n",
        "\n",
        "    # save the snapshot of the model to local drive\n",
        "    pretrain_model_name = 'pretrained_{}_{}_{}_{}.h5'.format(model_name, num_class, epochs, suffix)\n",
        "    # visualize the training process\n",
        "    tensorboard = TensorBoard(log_dir=\"logs/{}_pretrain_{}\".format(model_name, time()), histogram_freq=0, write_graph=True)\n",
        "    checkpoint = ModelCheckpoint(pretrain_model_name, monitor='val_acc', verbose=1, save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
        "    callbacks_list = [checkpoint, tensorboard]\n",
        "\n",
        "    model.fit_generator(\n",
        "        train_generator,\n",
        "        steps_per_epoch=stepsPerEpoch,\n",
        "        epochs=epochs,\n",
        "        callbacks = callbacks_list,\n",
        "        validation_data = validation_generator,\n",
        "        validation_steps=validationSteps)\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cR1uYZGLyP7u",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        ""
      ]
    },
    {
      "metadata": {
        "id": "6Yvky52W4-ty",
        "colab_type": "code",
        "outputId": "db295643-2b67-46a1-b918-f6308ab5e3ec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "cell_type": "code",
      "source": [
        "my_model_name='inception_v3'\n",
        "my_batch_size=32\n",
        "my_epochs=20\n",
        "model, train_generator, validation_generator = init_model(train_dir='drive/My Drive/train_folder', model_name=my_model_name, val_dir='drive/My Drive/test_folder',batch_size=my_batch_size, num_class=196)\n",
        "my_model=train(model, train_generator, validation_generator, model_name=my_model_name, num_class=196, batch_size=my_batch_size,epochs=my_epochs)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "loading the model and the pre-trained weights...\n",
            "Found 8144 images belonging to 196 classes.\n",
            "Found 8041 images belonging to 196 classes.\n",
            "Epoch 1/20\n",
            "  5/254 [..............................] - ETA: 1:08:03 - loss: 5.4896 - acc: 0.0000e+00"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "lD6dJdi8KOG3",
        "colab_type": "code",
        "outputId": "82fdfbe3-f0f5-4d78-a206-66ecf8513188",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "my_model.save('drive/My Drive/coerce_model.h5')\n",
        "print('Saved model to disk')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saved model to disk\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "nKhLWk7nJ33e",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def fine_tune(model,train_generator, validation_generator, model_name,\\\n",
        "              batch_size, epochs,num_class=196,suffix='laioffer'):\n",
        "    \"\"\"\n",
        "    fine tune the model\n",
        "    parms:\n",
        "        model: initialized model\n",
        "        train_generator: training data generator\n",
        "        validation_generator: validation data generator\n",
        "        args: parsed command line arguments\n",
        "    return:\n",
        "    \"\"\"\n",
        "    # for specific architectures, define number of trainable layers\n",
        "    if model_name == 'vgg16':\n",
        "        trainable_layers = 6\n",
        "    elif model_name == 'inception_v3':\n",
        "        trainable_layers = 35\n",
        "    elif model_name == 'resnet50':\n",
        "        trainable_layers = 12\n",
        "\n",
        "    for layer in model.layers[:-1*trainable_layers]:\n",
        "        layer.trainable = False\n",
        "\n",
        "    for layer in model.layers[-1*trainable_layers:]:\n",
        "        layer.trainable = True\n",
        "\n",
        "    finetune_model_name = 'finetuned_{}_{}_{}_{}.h5'.format(model_name, num_class, \\\n",
        "                                                            epochs, suffix)\n",
        "    tensorboard = TensorBoard(log_dir=\"logs/{}_finetune_{}\".format(model_name, time()), histogram_freq=0, write_graph=True)\n",
        "    checkpoint = ModelCheckpoint(finetune_model_name, monitor='val_acc', verbose=1, save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
        "    callbacks_list = [checkpoint, tensorboard]\n",
        "\n",
        "    model.compile(loss=\"categorical_crossentropy\", optimizer=optimizers.SGD(lr=0.01, momentum=0.9),metrics=[\"accuracy\"])\n",
        "\n",
        "    stepsPerEpoch = train_generator.samples / batch_size\n",
        "    validationSteps= validation_generator.samples / batch_size\n",
        "    model.fit_generator(\n",
        "        train_generator,\n",
        "        steps_per_epoch=stepsPerEpoch,\n",
        "        epochs=epochs + 50,\n",
        "        callbacks = callbacks_list,\n",
        "        validation_data = validation_generator,\n",
        "        validation_steps=validationSteps)\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "h2NwJo4MKDnv",
        "colab_type": "code",
        "outputId": "baddf827-d576-49b9-9902-0e883981dcf5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 4290
        }
      },
      "cell_type": "code",
      "source": [
        "my_model=fine_tune(my_model, train_generator, validation_generator, model_name=my_model_name\\\n",
        "          ,batch_size=my_batch_size,epochs=my_epochs)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/70\n",
            "82/81 [==============================] - 233s 3s/step - loss: 1.9167 - acc: 0.5294 - val_loss: 6.3440 - val_acc: 0.0761\n",
            "\n",
            "Epoch 00001: val_acc improved from -inf to 0.07611, saving model to finetuned_inception_v3_196_20_laioffer.h5\n",
            "Epoch 2/70\n",
            "82/81 [==============================] - 221s 3s/step - loss: 1.8273 - acc: 0.5670 - val_loss: 6.2699 - val_acc: 0.0755\n",
            "\n",
            "Epoch 00002: val_acc did not improve from 0.07611\n",
            "Epoch 3/70\n",
            "82/81 [==============================] - 217s 3s/step - loss: 1.7690 - acc: 0.5773 - val_loss: 6.2411 - val_acc: 0.0764\n",
            "\n",
            "Epoch 00003: val_acc improved from 0.07611 to 0.07636, saving model to finetuned_inception_v3_196_20_laioffer.h5\n",
            "Epoch 4/70\n",
            "82/81 [==============================] - 217s 3s/step - loss: 1.7439 - acc: 0.5788 - val_loss: 6.2277 - val_acc: 0.0775\n",
            "\n",
            "Epoch 00004: val_acc improved from 0.07636 to 0.07748, saving model to finetuned_inception_v3_196_20_laioffer.h5\n",
            "Epoch 5/70\n",
            "82/81 [==============================] - 211s 3s/step - loss: 1.7008 - acc: 0.5969 - val_loss: 6.2184 - val_acc: 0.0772\n",
            "\n",
            "Epoch 00005: val_acc did not improve from 0.07748\n",
            "Epoch 6/70\n",
            "82/81 [==============================] - 215s 3s/step - loss: 1.6543 - acc: 0.6067 - val_loss: 6.2024 - val_acc: 0.0782\n",
            "\n",
            "Epoch 00006: val_acc improved from 0.07748 to 0.07822, saving model to finetuned_inception_v3_196_20_laioffer.h5\n",
            "Epoch 7/70\n",
            "82/81 [==============================] - 212s 3s/step - loss: 1.6375 - acc: 0.6111 - val_loss: 6.1937 - val_acc: 0.0787\n",
            "\n",
            "Epoch 00007: val_acc improved from 0.07822 to 0.07872, saving model to finetuned_inception_v3_196_20_laioffer.h5\n",
            "Epoch 8/70\n",
            "82/81 [==============================] - 219s 3s/step - loss: 1.6124 - acc: 0.6223 - val_loss: 6.1917 - val_acc: 0.0790\n",
            "\n",
            "Epoch 00008: val_acc improved from 0.07872 to 0.07897, saving model to finetuned_inception_v3_196_20_laioffer.h5\n",
            "Epoch 9/70\n",
            "82/81 [==============================] - 211s 3s/step - loss: 1.5675 - acc: 0.6316 - val_loss: 6.1828 - val_acc: 0.0811\n",
            "\n",
            "Epoch 00009: val_acc improved from 0.07897 to 0.08108, saving model to finetuned_inception_v3_196_20_laioffer.h5\n",
            "Epoch 10/70\n",
            "82/81 [==============================] - 215s 3s/step - loss: 1.5545 - acc: 0.6385 - val_loss: 6.1940 - val_acc: 0.0808\n",
            "\n",
            "Epoch 00010: val_acc did not improve from 0.08108\n",
            "Epoch 11/70\n",
            "82/81 [==============================] - 218s 3s/step - loss: 1.5257 - acc: 0.6476 - val_loss: 6.1711 - val_acc: 0.0820\n",
            "\n",
            "Epoch 00011: val_acc improved from 0.08108 to 0.08195, saving model to finetuned_inception_v3_196_20_laioffer.h5\n",
            "Epoch 12/70\n",
            "82/81 [==============================] - 212s 3s/step - loss: 1.5106 - acc: 0.6468 - val_loss: 6.1703 - val_acc: 0.0820\n",
            "\n",
            "Epoch 00012: val_acc did not improve from 0.08195\n",
            "Epoch 13/70\n",
            "82/81 [==============================] - 213s 3s/step - loss: 1.4778 - acc: 0.6598 - val_loss: 6.1627 - val_acc: 0.0831\n",
            "\n",
            "Epoch 00013: val_acc improved from 0.08195 to 0.08307, saving model to finetuned_inception_v3_196_20_laioffer.h5\n",
            "Epoch 14/70\n",
            "82/81 [==============================] - 215s 3s/step - loss: 1.4473 - acc: 0.6653 - val_loss: 6.1563 - val_acc: 0.0831\n",
            "\n",
            "Epoch 00014: val_acc did not improve from 0.08307\n",
            "Epoch 15/70\n",
            "82/81 [==============================] - 214s 3s/step - loss: 1.4261 - acc: 0.6752 - val_loss: 6.1257 - val_acc: 0.0846\n",
            "\n",
            "Epoch 00015: val_acc improved from 0.08307 to 0.08457, saving model to finetuned_inception_v3_196_20_laioffer.h5\n",
            "Epoch 16/70\n",
            "82/81 [==============================] - 215s 3s/step - loss: 1.4121 - acc: 0.6757 - val_loss: 6.1205 - val_acc: 0.0848\n",
            "\n",
            "Epoch 00016: val_acc improved from 0.08457 to 0.08482, saving model to finetuned_inception_v3_196_20_laioffer.h5\n",
            "Epoch 17/70\n",
            "82/81 [==============================] - 214s 3s/step - loss: 1.3864 - acc: 0.6799 - val_loss: 6.1103 - val_acc: 0.0856\n",
            "\n",
            "Epoch 00017: val_acc improved from 0.08482 to 0.08556, saving model to finetuned_inception_v3_196_20_laioffer.h5\n",
            "Epoch 18/70\n",
            "82/81 [==============================] - 216s 3s/step - loss: 1.3486 - acc: 0.6911 - val_loss: 6.0965 - val_acc: 0.0862\n",
            "\n",
            "Epoch 00018: val_acc improved from 0.08556 to 0.08618, saving model to finetuned_inception_v3_196_20_laioffer.h5\n",
            "Epoch 19/70\n",
            "82/81 [==============================] - 217s 3s/step - loss: 1.3379 - acc: 0.6967 - val_loss: 6.1047 - val_acc: 0.0856\n",
            "\n",
            "Epoch 00019: val_acc did not improve from 0.08618\n",
            "Epoch 20/70\n",
            "82/81 [==============================] - 212s 3s/step - loss: 1.3161 - acc: 0.7075 - val_loss: 6.1084 - val_acc: 0.0862\n",
            "\n",
            "Epoch 00020: val_acc improved from 0.08618 to 0.08618, saving model to finetuned_inception_v3_196_20_laioffer.h5\n",
            "Epoch 21/70\n",
            "82/81 [==============================] - 215s 3s/step - loss: 1.3034 - acc: 0.7089 - val_loss: 6.1122 - val_acc: 0.0879\n",
            "\n",
            "Epoch 00021: val_acc improved from 0.08618 to 0.08792, saving model to finetuned_inception_v3_196_20_laioffer.h5\n",
            "Epoch 22/70\n",
            "82/81 [==============================] - 217s 3s/step - loss: 1.2776 - acc: 0.7205 - val_loss: 6.1060 - val_acc: 0.0878\n",
            "\n",
            "Epoch 00022: val_acc did not improve from 0.08792\n",
            "Epoch 23/70\n",
            "82/81 [==============================] - 213s 3s/step - loss: 1.2592 - acc: 0.7175 - val_loss: 6.1221 - val_acc: 0.0880\n",
            "\n",
            "Epoch 00023: val_acc improved from 0.08792 to 0.08805, saving model to finetuned_inception_v3_196_20_laioffer.h5\n",
            "Epoch 24/70\n",
            "82/81 [==============================] - 214s 3s/step - loss: 1.2395 - acc: 0.7278 - val_loss: 6.1237 - val_acc: 0.0887\n",
            "\n",
            "Epoch 00024: val_acc improved from 0.08805 to 0.08867, saving model to finetuned_inception_v3_196_20_laioffer.h5\n",
            "Epoch 25/70\n",
            "82/81 [==============================] - 220s 3s/step - loss: 1.2107 - acc: 0.7375 - val_loss: 6.1131 - val_acc: 0.0885\n",
            "\n",
            "Epoch 00025: val_acc did not improve from 0.08867\n",
            "Epoch 26/70\n",
            "82/81 [==============================] - 211s 3s/step - loss: 1.2085 - acc: 0.7394 - val_loss: 6.1175 - val_acc: 0.0889\n",
            "\n",
            "Epoch 00026: val_acc improved from 0.08867 to 0.08892, saving model to finetuned_inception_v3_196_20_laioffer.h5\n",
            "Epoch 27/70\n",
            "82/81 [==============================] - 213s 3s/step - loss: 1.1935 - acc: 0.7420 - val_loss: 6.1026 - val_acc: 0.0898\n",
            "\n",
            "Epoch 00027: val_acc improved from 0.08892 to 0.08979, saving model to finetuned_inception_v3_196_20_laioffer.h5\n",
            "Epoch 28/70\n",
            "82/81 [==============================] - 219s 3s/step - loss: 1.1667 - acc: 0.7462 - val_loss: 6.1089 - val_acc: 0.0909\n",
            "\n",
            "Epoch 00028: val_acc improved from 0.08979 to 0.09091, saving model to finetuned_inception_v3_196_20_laioffer.h5\n",
            "Epoch 29/70\n",
            "82/81 [==============================] - 215s 3s/step - loss: 1.1500 - acc: 0.7503 - val_loss: 6.1090 - val_acc: 0.0904\n",
            "\n",
            "Epoch 00029: val_acc did not improve from 0.09091\n",
            "Epoch 30/70\n",
            "82/81 [==============================] - 217s 3s/step - loss: 1.1280 - acc: 0.7614 - val_loss: 6.1034 - val_acc: 0.0909\n",
            "\n",
            "Epoch 00030: val_acc did not improve from 0.09091\n",
            "Epoch 31/70\n",
            "82/81 [==============================] - 214s 3s/step - loss: 1.1076 - acc: 0.7649 - val_loss: 6.1061 - val_acc: 0.0912\n",
            "\n",
            "Epoch 00031: val_acc improved from 0.09091 to 0.09116, saving model to finetuned_inception_v3_196_20_laioffer.h5\n",
            "Epoch 32/70\n",
            "82/81 [==============================] - 216s 3s/step - loss: 1.1060 - acc: 0.7670 - val_loss: 6.1110 - val_acc: 0.0905\n",
            "\n",
            "Epoch 00032: val_acc did not improve from 0.09116\n",
            "Epoch 33/70\n",
            "82/81 [==============================] - 216s 3s/step - loss: 1.0935 - acc: 0.7725 - val_loss: 6.0937 - val_acc: 0.0914\n",
            "\n",
            "Epoch 00033: val_acc improved from 0.09116 to 0.09141, saving model to finetuned_inception_v3_196_20_laioffer.h5\n",
            "Epoch 34/70\n",
            "82/81 [==============================] - 218s 3s/step - loss: 1.0751 - acc: 0.7762 - val_loss: 6.1079 - val_acc: 0.0909\n",
            "\n",
            "Epoch 00034: val_acc did not improve from 0.09141\n",
            "Epoch 35/70\n",
            "82/81 [==============================] - 216s 3s/step - loss: 1.0567 - acc: 0.7823 - val_loss: 6.1198 - val_acc: 0.0915\n",
            "\n",
            "Epoch 00035: val_acc improved from 0.09141 to 0.09153, saving model to finetuned_inception_v3_196_20_laioffer.h5\n",
            "Epoch 36/70\n",
            "82/81 [==============================] - 214s 3s/step - loss: 1.0481 - acc: 0.7824 - val_loss: 6.1106 - val_acc: 0.0922\n",
            "\n",
            "Epoch 00036: val_acc improved from 0.09153 to 0.09215, saving model to finetuned_inception_v3_196_20_laioffer.h5\n",
            "Epoch 37/70\n",
            "82/81 [==============================] - 220s 3s/step - loss: 1.0249 - acc: 0.7909 - val_loss: 6.1216 - val_acc: 0.0920\n",
            "\n",
            "Epoch 00037: val_acc did not improve from 0.09215\n",
            "Epoch 38/70\n",
            "82/81 [==============================] - 215s 3s/step - loss: 1.0146 - acc: 0.7941 - val_loss: 6.1268 - val_acc: 0.0918\n",
            "\n",
            "Epoch 00038: val_acc did not improve from 0.09215\n",
            "Epoch 39/70\n",
            "82/81 [==============================] - 218s 3s/step - loss: 0.9970 - acc: 0.8048 - val_loss: 6.1331 - val_acc: 0.0922\n",
            "\n",
            "Epoch 00039: val_acc improved from 0.09215 to 0.09215, saving model to finetuned_inception_v3_196_20_laioffer.h5\n",
            "Epoch 40/70\n",
            "82/81 [==============================] - 217s 3s/step - loss: 0.9771 - acc: 0.8073 - val_loss: 6.1321 - val_acc: 0.0922\n",
            "\n",
            "Epoch 00040: val_acc did not improve from 0.09215\n",
            "Epoch 41/70\n",
            "82/81 [==============================] - 220s 3s/step - loss: 0.9686 - acc: 0.8097 - val_loss: 6.1196 - val_acc: 0.0936\n",
            "\n",
            "Epoch 00041: val_acc improved from 0.09215 to 0.09365, saving model to finetuned_inception_v3_196_20_laioffer.h5\n",
            "Epoch 42/70\n",
            "82/81 [==============================] - 219s 3s/step - loss: 0.9568 - acc: 0.8121 - val_loss: 6.0914 - val_acc: 0.0934\n",
            "\n",
            "Epoch 00042: val_acc did not improve from 0.09365\n",
            "Epoch 43/70\n",
            "82/81 [==============================] - 221s 3s/step - loss: 0.9444 - acc: 0.8169 - val_loss: 6.1060 - val_acc: 0.0945\n",
            "\n",
            "Epoch 00043: val_acc improved from 0.09365 to 0.09452, saving model to finetuned_inception_v3_196_20_laioffer.h5\n",
            "Epoch 44/70\n",
            "82/81 [==============================] - 221s 3s/step - loss: 0.9285 - acc: 0.8227 - val_loss: 6.1307 - val_acc: 0.0930\n",
            "\n",
            "Epoch 00044: val_acc did not improve from 0.09452\n",
            "Epoch 45/70\n",
            "82/81 [==============================] - 222s 3s/step - loss: 0.9101 - acc: 0.8281 - val_loss: 6.1110 - val_acc: 0.0938\n",
            "\n",
            "Epoch 00045: val_acc did not improve from 0.09452\n",
            "Epoch 46/70\n",
            "82/81 [==============================] - 222s 3s/step - loss: 0.8940 - acc: 0.8309 - val_loss: 6.1249 - val_acc: 0.0941\n",
            "\n",
            "Epoch 00046: val_acc did not improve from 0.09452\n",
            "Epoch 47/70\n",
            "82/81 [==============================] - 221s 3s/step - loss: 0.9002 - acc: 0.8314 - val_loss: 6.1283 - val_acc: 0.0946\n",
            "\n",
            "Epoch 00047: val_acc improved from 0.09452 to 0.09464, saving model to finetuned_inception_v3_196_20_laioffer.h5\n",
            "Epoch 48/70\n",
            "82/81 [==============================] - 225s 3s/step - loss: 0.8807 - acc: 0.8378 - val_loss: 6.1394 - val_acc: 0.0939\n",
            "\n",
            "Epoch 00048: val_acc did not improve from 0.09464\n",
            "Epoch 49/70\n",
            "82/81 [==============================] - 219s 3s/step - loss: 0.8622 - acc: 0.8454 - val_loss: 6.1425 - val_acc: 0.0936\n",
            "\n",
            "Epoch 00049: val_acc did not improve from 0.09464\n",
            "Epoch 50/70\n",
            "82/81 [==============================] - 213s 3s/step - loss: 0.8652 - acc: 0.8408 - val_loss: 6.1412 - val_acc: 0.0940\n",
            "\n",
            "Epoch 00050: val_acc did not improve from 0.09464\n",
            "Epoch 51/70\n",
            "82/81 [==============================] - 212s 3s/step - loss: 0.8441 - acc: 0.8493 - val_loss: 6.1381 - val_acc: 0.0939\n",
            "\n",
            "Epoch 00051: val_acc did not improve from 0.09464\n",
            "Epoch 52/70\n",
            "82/81 [==============================] - 211s 3s/step - loss: 0.8348 - acc: 0.8483 - val_loss: 6.1462 - val_acc: 0.0941\n",
            "\n",
            "Epoch 00052: val_acc did not improve from 0.09464\n",
            "Epoch 53/70\n",
            "82/81 [==============================] - 209s 3s/step - loss: 0.8086 - acc: 0.8618 - val_loss: 6.1348 - val_acc: 0.0950\n",
            "\n",
            "Epoch 00053: val_acc improved from 0.09464 to 0.09501, saving model to finetuned_inception_v3_196_20_laioffer.h5\n",
            "Epoch 54/70\n",
            "82/81 [==============================] - 216s 3s/step - loss: 0.8140 - acc: 0.8573 - val_loss: 6.1473 - val_acc: 0.0945\n",
            "\n",
            "Epoch 00054: val_acc did not improve from 0.09501\n",
            "Epoch 55/70\n",
            "82/81 [==============================] - 213s 3s/step - loss: 0.7971 - acc: 0.8595 - val_loss: 6.1319 - val_acc: 0.0939\n",
            "\n",
            "Epoch 00055: val_acc did not improve from 0.09501\n",
            "Epoch 56/70\n",
            "82/81 [==============================] - 210s 3s/step - loss: 0.7910 - acc: 0.8640 - val_loss: 6.1248 - val_acc: 0.0948\n",
            "\n",
            "Epoch 00056: val_acc did not improve from 0.09501\n",
            "Epoch 57/70\n",
            "82/81 [==============================] - 213s 3s/step - loss: 0.7716 - acc: 0.8695 - val_loss: 6.1247 - val_acc: 0.0949\n",
            "\n",
            "Epoch 00057: val_acc did not improve from 0.09501\n",
            "Epoch 58/70\n",
            "82/81 [==============================] - 210s 3s/step - loss: 0.7677 - acc: 0.8725 - val_loss: 6.1344 - val_acc: 0.0933\n",
            "\n",
            "Epoch 00058: val_acc did not improve from 0.09501\n",
            "Epoch 59/70\n",
            "82/81 [==============================] - 211s 3s/step - loss: 0.7553 - acc: 0.8761 - val_loss: 6.1627 - val_acc: 0.0929\n",
            "\n",
            "Epoch 00059: val_acc did not improve from 0.09501\n",
            "Epoch 60/70\n",
            "82/81 [==============================] - 210s 3s/step - loss: 0.7348 - acc: 0.8843 - val_loss: 6.1338 - val_acc: 0.0945\n",
            "\n",
            "Epoch 00060: val_acc did not improve from 0.09501\n",
            "Epoch 61/70\n",
            "47/81 [================>.............] - ETA: 35s - loss: 0.7394 - acc: 0.8815"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "oVcRmRhVRze2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model_json = my_model.to_json()\n",
        "with open(\"drive/My Drive/tunned_model.json\", \"w\") as json_file:\n",
        "    json_file.write(model_json)\n",
        "# serialize weights to HDF5\n",
        "my_model.save_weights(\"drive/My Drive/tunned_model.h5\")\n",
        "print(\"Saved model to disk\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Jc8--9y-pkLe",
        "colab_type": "code",
        "outputId": "64b6e15d-a81a-4f91-ee29-1973e964ef10",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "from keras.preprocessing import image\n",
        "from keras.applications import vgg16\n",
        "from keras.applications import vgg19\n",
        "from keras.applications import resnet50\n",
        "from keras.applications import inception_v3\n",
        "from keras.layers import GlobalAveragePooling2D, Dense, Dropout, Flatten\n",
        "from keras.models import Model, Sequential, load_model\n",
        "from keras import optimizers \n",
        "from keras.callbacks import TensorBoard, ModelCheckpoint\n",
        "\n",
        "from keras.preprocessing.image import load_img\n",
        "from keras.preprocessing.image import img_to_array\n",
        "\n",
        "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "import argparse\n",
        "import os\n",
        "import glob\n",
        "\n",
        "from keras import backend as K\n",
        "K.set_image_dim_ordering('tf')\n",
        "# K.set_learning_phase(0)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "2suTFVskrsk6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def predict(model_name,test_dir,model_weight_name,img_size=224):\n",
        "    # load preprocess func\n",
        "    if model_name == 'vgg19':\n",
        "        # base_model = vgg19.VGG19(include_top=False, weights=None, input_shape = (224,224,3)) # need specify input_shape\n",
        "        preprocess_input = vgg19.preprocess_input\n",
        "    elif model_name == 'inception_v3':\n",
        "        # base_model = inception_v3.InceptionV3(include_top=False, weights=None, input_shape = (224,224,3)) # need specify input_shape\n",
        "        preprocess_input = inception_v3.preprocess_input\n",
        "    elif model_name == 'resnet50':\n",
        "        # base_model = resnet50.ResNet50(include_top=False, weights=None, input_shape = (224,224,3)) # need specify input_shape\n",
        "        preprocess_input = resnet50.preprocess_input\n",
        "\n",
        "    test_datagen = image.ImageDataGenerator(\n",
        "        preprocessing_function=preprocess_input\n",
        "        )\n",
        "    test_generator = test_datagen.flow_from_directory(\n",
        "        test_dir,\n",
        "        target_size=(img_size, img_size),\n",
        "        batch_size=1,\n",
        "        shuffle=False,\n",
        "        class_mode='categorical')\n",
        "\n",
        "    # fnames = test_generator.filenames\n",
        "    # label_map = test_generator.class_indices\n",
        "    true_labels = test_generator.classes\n",
        "\n",
        "    # load model\n",
        "    model = load_model(model_weight_name)\n",
        "\n",
        "    predicted_label_probs = model.predict_generator(test_generator, verbose=1)\n",
        "    predicted_labels = np.argmax(predicted_label_probs, axis=1)\n",
        "\n",
        "    # print(confusion_matrix(true_labels, predicted_labels))\n",
        "    # print(classification_report(true_labels, predicted_labels))\n",
        "    print(\"Accuracy = \", accuracy_score(true_labels, predicted_labels))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3htT4aG9uSDN",
        "colab_type": "code",
        "outputId": "204f4fbd-88c4-4c51-abc4-440dbbbc18a4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 451
        }
      },
      "cell_type": "code",
      "source": [
        "predict(model_name='inception_v3',test_dir='drive/My Drive/test_folder',model_weight_name='drive/My Drive/model.h5')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 8041 images belonging to 196 classes.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-aa69808ddf8a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'inception_v3'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'drive/My Drive/test_folder'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodel_weight_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'drive/My Drive/model.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-4-36866845460c>\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(model_name, test_dir, model_weight_name, img_size)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0;31m# load model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_weight_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0mpredicted_label_probs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_generator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/models.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile)\u001b[0m\n\u001b[1;32m    266\u001b[0m         \u001b[0mmodel_config\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'model_config'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmodel_config\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 268\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'No model found in config file.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    269\u001b[0m         \u001b[0mmodel_config\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_config\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_from_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_config\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcustom_objects\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: No model found in config file."
          ]
        }
      ]
    }
  ]
}